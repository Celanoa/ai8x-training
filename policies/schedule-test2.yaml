lr_schedulers:
  training_lr:
    class: ExponentialLR
    gamma: 0.98

policies:
  - lr_scheduler:
      instance_name: training_lr
    starting_epoch: 0
    ending_epoch: 200
    frequency: 1
